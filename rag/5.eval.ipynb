{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%pip install --upgrade --quiet pip setuptools wheel matplotlib seaborn\n",
    "%pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken crate 'crate[sqlalchemy]' pandas jq \n",
    "%pip install --use-pep517 --quiet python-dotenv\n",
    "%pip install --quiet langchain-google-genai\n",
    "%pip install -qU langchain-anthropic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T20:40:01.733206Z",
     "start_time": "2024-05-25T20:39:53.723438Z"
    }
   },
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate RAG search with CrateDB vector, fulltext, fusion and OpenAI",
   "id": "5410104937328c86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup environment variables",
   "id": "26168fafe85c0e89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:40:01.740962Z",
     "start_time": "2024-05-25T20:40:01.734223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "e4a28f2ab8e8b4df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## setup embeddings",
   "id": "331beb594f3a2037"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:40:02.730991Z",
     "start_time": "2024-05-25T20:40:01.741493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "len(embeddings.embed_query(\"a\"))"
   ],
   "id": "ae2043d7eec255f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:40:02.734883Z",
     "start_time": "2024-05-25T20:40:02.732286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn_url = \"crate://{user}:{password}@{server}\".format(\n",
    "    user=os.environ[\"CRATEDB_USER\"],\n",
    "    password=os.environ[\"CRATEDB_PASS\"],\n",
    "    server=os.environ[\"CRATEDB_SERVER\"],\n",
    ")\n",
    "conn_url"
   ],
   "id": "de9c0e56bb15743f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crate://crate:@localhost:4200'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:40:03.986849Z",
     "start_time": "2024-05-25T20:40:02.735754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# open file\n",
    "from langchain_community.document_loaders import JSONLoader, DirectoryLoader\n",
    "\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"source_url\"] = record.get(\"url\")\n",
    "    metadata[\"source_title\"] = record.get(\"title\")\n",
    "\n",
    "    if \"source\" in metadata:\n",
    "        metadata[\"source\"] = metadata[\"source_url\"]\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    './',\n",
    "    glob=\"everything-*.json\",\n",
    "    loader_cls=JSONLoader,\n",
    "    loader_kwargs={\n",
    "        \"jq_schema\": \".[]\",\n",
    "        \"text_content\": False,\n",
    "        \"content_key\": \"html\",\n",
    "        \"metadata_func\": metadata_func,\n",
    "    }\n",
    ")\n",
    "\n",
    "data = loader.load()\n",
    "# data[:1]"
   ],
   "id": "44bfb1096b01b12b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:40:25.188002Z",
     "start_time": "2024-05-25T20:40:24.029584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split documents\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "    ],\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "docs_splits = text_splitter.split_documents(data)\n",
    "# docs_splits[:2]"
   ],
   "id": "5ae87cfd6c484e9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG search, indexing pipeline    ",
   "id": "a0afa7c55d8d850b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:40:27.436825Z",
     "start_time": "2024-05-25T20:40:27.138608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic\n"
   ],
   "id": "f595efc8735a31cc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:32.236306Z",
     "start_time": "2024-05-25T20:40:28.214431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.vectorstore.crate import CrateVectorStore\n",
    "\n",
    "vectorstore = CrateVectorStore.from_documents(\n",
    "    # assumes that data was imported already\n",
    "    # allow faster recomputation of notebook, without need of reindexing\n",
    "    # documents=[],\n",
    "    documents=docs_splits,\n",
    "    embedding=embeddings,\n",
    "    database_kwargs={\n",
    "        \"database_uri\": conn_url,\n",
    "    },\n",
    "    vectorstore_kwargs={\n",
    "        \"drop_if_exists\": True,\n",
    "    },\n",
    ")\n",
    "vectorstore"
   ],
   "id": "665ce2d16282637f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rag.vectorstore.crate.CrateVectorStore at 0x30d0ff510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:32.291774Z",
     "start_time": "2024-05-25T20:49:32.237453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_a = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 10, 'fetch_k': 30, \"algorith\": \"knn\"}\n",
    ")\n",
    "\n",
    "retriever_b = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 10, 'fetch_k': 30, \"algorith\": \"fulltext\"}\n",
    ")\n",
    "\n",
    "retriever_c = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        retriever_a,\n",
    "        retriever_b\n",
    "    ],\n",
    "    weights=[0.5, 0.5],\n",
    ")"
   ],
   "id": "4a0394754e9ac93d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:32.302436Z",
     "start_time": "2024-05-25T20:49:32.300196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator=\". \")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.92)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, redundant_filter, relevant_filter]\n",
    ")\n",
    "retriever_d = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor,\n",
    "    base_retriever=retriever_c,\n",
    ")"
   ],
   "id": "781dc12e0c5b9fa7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:32.304451Z",
     "start_time": "2024-05-25T20:49:32.302964Z"
    }
   },
   "cell_type": "code",
   "source": "import json",
   "id": "11bbcee8796a3715",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:34.697493Z",
     "start_time": "2024-05-25T20:49:32.304930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "template = \"\"\"Answer the question based only on the context, if possible use links to reference the source, use markdown, avoid answering when the context and question are not related.\n",
    "\n",
    "today date is 2024 April 3rd\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model_openai = ChatOpenAI()\n",
    "model_geminai = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "model_cloude = ChatAnthropic(model=\"claude-3-opus-20240229\", temperature=0.1)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    breakpoint()\n",
    "    return json.dumps([{\"text\": d.page_content, \"source\": d.metadata.get('source')} for d in docs])\n",
    "\n",
    "\n",
    "chain_a = (\n",
    "        {\"context\": retriever_a | format_docs,\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_b = (\n",
    "        {\"context\": retriever_b | format_docs,\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_c = (\n",
    "        {\"context\": retriever_c | format_docs,\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_d = (\n",
    "        {\"context\": retriever_d | format_docs,\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# result = chain.invoke(\"How to limit permissions?\")\n",
    "# result = chain.invoke(\" How AWS marketplace works, and why I cannot see deployment in my account?\")\n",
    "# result = chain.invoke(\"What are edge regions and how to use them?\")\n",
    "# result = chain_a.invoke(\"Write me example of using blobs?\")\n",
    "result = chain_d.invoke(\"Write me example of using blobs?\")\n",
    "# result = chain.invoke(\"How to use BLOB store in CrateDB? and what are the benefits?\")\n",
    "result\n"
   ],
   "id": "76601e20f9f80251",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but without any specific context or reference to blobs, I cannot provide a relevant answer to your question.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:43.528696Z",
     "start_time": "2024-05-25T20:49:34.698331Z"
    }
   },
   "cell_type": "code",
   "source": "model_cloude.invoke(\"Write me poem\")",
   "id": "4bc01063681dba7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's a poem for you:\\n\\nIn the tapestry of life, threads intertwine,\\nWeaving moments of joy, love, and sometimes pain.\\nEach stitch a memory, a story to tell,\\nOf laughter, tears, and dreams that dwell.\\n\\nColors blend and patterns form,\\nCreating a masterpiece, vibrant and warm.\\nThrough the ups and downs, the twists and turns,\\nThe fabric of existence forever churns.\\n\\nYet in the midst of chaos and strife,\\nThere's beauty to be found, a zest for life.\\nIn the simple things, the everyday,\\nA smile, a hug, a word to say.\\n\\nSo let us cherish the moments we hold dear,\\nAnd face the future without fear.\\nFor in this grand design, we play a part,\\nStitching our stories, with love in our heart.\", response_metadata={'id': 'msg_013mLhrKS5DZTGVGuBmnU98o', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 10, 'output_tokens': 196}}, id='run-51e2e4f7-83d0-408c-a21b-243b07225684-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:47.802641Z",
     "start_time": "2024-05-25T20:49:43.529766Z"
    }
   },
   "cell_type": "code",
   "source": "model_geminai.invoke(\"Write me poem\")",
   "id": "3e1b6d3fcc0cd255",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"**Ode to the Evening Star**\\n\\nOh, Evening Star, with shimmering light,\\nA beacon in the fading night.\\nYour presence fills the twilight's embrace,\\nA celestial gem in time and space.\\n\\nYour twinkling dance, a graceful sway,\\nInvites the darkness to give way.\\nA harbinger of dreams to come,\\nGuiding weary souls to their home.\\n\\nAs stars ignite and paint the sky,\\nYou stand aloof, a watchful eye.\\nA silent guardian, ever bright,\\nDispelling shadows with your light.\\n\\nThe nightingale's sweet serenade,\\nEchoes through the moonlit glade.\\nAnd crickets chirp their gentle tune,\\nA symphony beneath the moon.\\n\\nOh, Evening Star, with radiance true,\\nYou bring us solace, me and you.\\nA beacon of hope, a guiding light,\\nIn the tapestry of the starry night.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-b1099af5-620d-4bd7-9645-59c675d2ffe9-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(result))"
   ],
   "id": "30b414b6a3321c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "b1aed295b7496890"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:47.806193Z",
     "start_time": "2024-05-25T20:49:47.803885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "questions = [\n",
    "    \"Write me example of using blobs?\",\n",
    "    \"How to use BLOB store in CrateDB? and what are the benefits?\",\n",
    "    \"How to limit permissions?\",\n",
    "    \"How AWS marketplace works, and why I cannot see deployment in my account?\",\n",
    "    \"What are edge regions and how to use them?\",\n",
    "    \"What are recent blog posts about CrateDB?\",\n",
    "    \"Write me example python code to use CrateDB?\",\n",
    "    \"Write me example golang code to use CrateDB?\",\n",
    "    \"create RAG search with CrateDB and OpenAI?\",\n",
    "    \"how to alter table and add fulltext index?\",\n",
    "    \"how to alter table and add vector type field that allows for KNN search?\",\n",
    "    \"create table with fields ID, name, vector, and index vector field for KNN search?\",\n",
    "    \"What are limits and limitations of CrateDB?\",\n",
    "    \"What are the benefits of using CrateDB?\",\n",
    "    \"Does index creation block write operations?\",\n",
    "    \"Does crate supports conditional indices\",\n",
    "    \"How to create ID field that is autoincremented?\",\n",
    "    \"how to create analysers for fulltext search?\",\n",
    "    \"give me information about password and admin\",\n",
    "    \"Shared file system implementation of the BlobStoreRepository\",\n",
    "    \"Is Cloud UI opensource?\",\n",
    "    \"How to do fusion search and connect vector search with fulltext search\",\n",
    "    \"How to MATH fulltext \"\n",
    "    \"Benchmarks of CrateDB\",\n",
    "]"
   ],
   "id": "cede734d54699adc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:49:47.861884Z",
     "start_time": "2024-05-25T20:49:47.808757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "# from langchain.evaluation.criteria import Criteria\n",
    "# \n",
    "# criteria = [\n",
    "#     Criteria.COHERENCE,\n",
    "#     Criteria.RELEVANCE,\n",
    "#     Criteria.DETAIL,\n",
    "#     Criteria.HARMFULNESS,\n",
    "#     Criteria.HELPFULNESS,\n",
    "# ]\n",
    "\n",
    "criteria2 = {\n",
    "    \"runnable\": \"Software engineer who is looking for information can copy and paste the code and it should work\",\n",
    "    \"relevance\": \"The answer is relevant to the question\",\n",
    "    \"grounded\": \"The answer links to the source of the information\",\n",
    "    \"coherence\": \"The answer is coherent and makes sense\",\n",
    "    \"detail\": \"The answer is detailed and provides enough information\",\n",
    "    \"helpfulness\": \"The answer is helpful and provides value\",\n",
    "    \"direct\": \"The answer directly answers the question\",\n",
    "    \"code\": \"The answer contains code that can be copied and pasted\",\n",
    "    \"reference\": \"The answer contains reference to the source in form of URL\",\n",
    "}\n",
    "\n",
    "evaluator_openai = load_evaluator(\"pairwise_string\", criteria=criteria2, llm=model_openai)\n",
    "evaluator_gemini = load_evaluator(\"pairwise_string\", criteria=criteria2, llm=model_geminai)\n",
    "evaluator_cloude = load_evaluator(\"pairwise_string\", criteria=criteria2, llm=model_cloude)\n"
   ],
   "id": "7f1528481846d709",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n",
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n",
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:50:02.036180Z",
     "start_time": "2024-05-25T20:49:47.862337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"Write me example of using blobs?\"\n",
    "prediction = chain_a.invoke(question)\n",
    "prediction_b = chain_b.invoke(question)\n",
    "\n",
    "ev = evaluator_cloude.evaluate_string_pairs(\n",
    "    prediction=prediction,\n",
    "    prediction_b=prediction_b,\n",
    "    input=question\n",
    ")\n",
    "\n"
   ],
   "id": "f46460593bc5d2d5",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:50:02.044861Z",
     "start_time": "2024-05-25T20:50:02.037604Z"
    }
   },
   "cell_type": "code",
   "source": "ev",
   "id": "2bfb0ad031d27cad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': \"After comparing the two responses, Assistant B's answer is better for the following reasons:\\n\\n1. Relevance and directness: Both answers are relevant and directly address the question of providing an example of using blobs. However, Assistant B's answer provides a more specific example by mentioning storing images separately from conventional data types in a database.\\n\\n2. Detail and helpfulness: Assistant B's response offers more detail by explaining that blobs allow for efficient storage and retrieval of large binary objects through applications like analytics or social networks. It also mentions the ability to define custom directory paths for storing blob data on different disks to optimize performance, which provides additional helpful information.\\n\\n3. Coherence: Both answers are coherent and make sense, but Assistant B's answer flows better by connecting the example to the benefits and practical considerations of using blobs.\\n\\n4. Reference: Both answers include a reference to the source of information (CrateDB blog), but Assistant B's answer integrates the source more smoothly into the response.\\n\\nWhile both answers are good, Assistant B's response is more detailed, helpful, and coherent, making it the better choice for the given criteria.\\n\\n[[B]]\",\n",
       " 'value': 'B',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:50:02.050033Z",
     "start_time": "2024-05-25T20:50:02.045603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class InferredRational(BaseModel):\n",
    "    rationale: str = Field(description=\"rational of the labeler\")\n",
    "    category: str = Field(description=\"category used for evaluation\")\n",
    "    # score: float = Field(\n",
    "    #     description=\"Score -1.5 to 1.5. Where -1.5 is below expectations in the rational category, and 1.5 is above expectations in the rational category.\")\n",
    "\n",
    "\n",
    "class RationalList(BaseModel):\n",
    "    list: List[InferredRational] = Field(description=\"list of rationals used to asses quality by labeler\")\n",
    "\n",
    "\n",
    "parser_ret = JsonOutputParser(pydantic_object=RationalList)\n",
    "\n",
    "prompt_reg = PromptTemplate(\n",
    "    template=\"Extract labeler rational following criterias {criterias}.\\n{format_instructions}\\n{reasoning}\\n\",\n",
    "    input_variables=[\"reasoning\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser_ret.get_format_instructions(),\n",
    "        \"criterias\": json.dumps(criteria2, indent=2)\n",
    "    },\n",
    ")\n",
    "\n",
    "chain_reasoning_extract = prompt_reg | model_openai | parser_ret\n",
    "\n",
    "\n",
    "def extract_reasoning(reasoning) -> RationalList:\n",
    "    try:\n",
    "        return chain_reasoning_extract.invoke({\"reasoning\": reasoning})\n",
    "    except BaseException as e:\n",
    "        return None"
   ],
   "id": "2330d5b9dacc75e1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:50:04.391467Z",
     "start_time": "2024-05-25T20:50:02.050857Z"
    }
   },
   "cell_type": "code",
   "source": "extract_reasoning(ev['reasoning'])",
   "id": "9da0a51fb09d76c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [{'rationale': 'The answer is relevant to the question and directly addresses the example of using blobs in a database',\n",
       "   'category': 'relevance'},\n",
       "  {'rationale': 'The answer is detailed and provides additional information about storing images separately and optimizing performance',\n",
       "   'category': 'detail'},\n",
       "  {'rationale': 'The answer is helpful by explaining the benefits and practical considerations of using blobs',\n",
       "   'category': 'helpfulness'},\n",
       "  {'rationale': 'The answer is coherent and connects the example to the benefits of using blobs in a logical way',\n",
       "   'category': 'coherence'},\n",
       "  {'rationale': 'The answer contains a reference to the source of information (CrateDB blog)',\n",
       "   'category': 'reference'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:50:04.396109Z",
     "start_time": "2024-05-25T20:50:04.392670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class TaggedQuestion(BaseModel):\n",
    "    question: str = Field(description=\"the original question\")\n",
    "    tags: List[str] = Field(description=\"the list of tags that best categorize the question\")\n",
    "\n",
    "\n",
    "class TaggedQuestionList(BaseModel):\n",
    "    list: List[TaggedQuestion] = Field(description=\"list of categorized questions\")\n",
    "\n",
    "\n",
    "parser_cat = JsonOutputParser(pydantic_object=TaggedQuestionList)\n",
    "\n",
    "prompt_cat = PromptTemplate(\n",
    "    template=\"Categorize question {questions}.\\n{format_instructions}\\n\\n\",\n",
    "    input_variables=[\"reasoning\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser_cat.get_format_instructions(),\n",
    "        \"questions\": json.dumps(questions, indent=2)\n",
    "    },\n",
    ")\n",
    "\n",
    "chain_tag_question = prompt_cat | model_openai | parser_cat\n",
    "\n",
    "\n",
    "def categorise_questions(questions: List[str]) -> TaggedQuestionList:\n",
    "    try:\n",
    "        return chain_tag_question.invoke({\"questions\": questions})\n",
    "    except BaseException as e:\n",
    "        return None"
   ],
   "id": "c7b2b72aaa04a542",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:50:13.582682Z",
     "start_time": "2024-05-25T20:50:04.396851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorised_questions = categorise_questions(questions)\n",
    "categorised_questions"
   ],
   "id": "153d4258ba9f1b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [{'question': 'Write me example of using blobs?',\n",
       "   'tags': ['Blob Storage']},\n",
       "  {'question': 'How to use BLOB store in CrateDB? and what are the benefits?',\n",
       "   'tags': ['Blob Storage', 'CrateDB']},\n",
       "  {'question': 'How to limit permissions?', 'tags': ['Permissions']},\n",
       "  {'question': 'How AWS marketplace works, and why I cannot see deployment in my account?',\n",
       "   'tags': ['AWS Marketplace']},\n",
       "  {'question': 'What are edge regions and how to use them?',\n",
       "   'tags': ['Edge Computing']},\n",
       "  {'question': 'What are recent blog posts about CrateDB?',\n",
       "   'tags': ['CrateDB', 'Blogs']},\n",
       "  {'question': 'Write me example python code to use CrateDB?',\n",
       "   'tags': ['CrateDB', 'Python']},\n",
       "  {'question': 'Write me example golang code to use CrateDB?',\n",
       "   'tags': ['CrateDB', 'Golang']},\n",
       "  {'question': 'create RAG search with CrateDB and OpenAI?',\n",
       "   'tags': ['CrateDB', 'OpenAI', 'Search']},\n",
       "  {'question': 'how to alter table and add fulltext index?',\n",
       "   'tags': ['CrateDB', 'Fulltext Index']},\n",
       "  {'question': 'how to alter table and add vector type field that allows for KNN search?',\n",
       "   'tags': ['CrateDB', 'Vector Type', 'KNN Search']},\n",
       "  {'question': 'create table with fields ID, name, vector, and index vector field for KNN search?',\n",
       "   'tags': ['CrateDB', 'Table Creation', 'KNN Search']},\n",
       "  {'question': 'What are limits and limitations of CrateDB?',\n",
       "   'tags': ['CrateDB', 'Limitations']},\n",
       "  {'question': 'What are the benefits of using CrateDB?',\n",
       "   'tags': ['CrateDB', 'Benefits']},\n",
       "  {'question': 'Does index creation block write operations?',\n",
       "   'tags': ['CrateDB', 'Indexing']},\n",
       "  {'question': 'Does crate supports conditional indices',\n",
       "   'tags': ['CrateDB', 'Conditional Indices']},\n",
       "  {'question': 'How to create ID field that is autoincremented?',\n",
       "   'tags': ['CrateDB', 'Autoincrement']},\n",
       "  {'question': 'how to create analysers for fulltext search?',\n",
       "   'tags': ['CrateDB', 'Fulltext Search', 'Analyzers']},\n",
       "  {'question': 'give me information about password and admin',\n",
       "   'tags': ['Security', 'Authentication']},\n",
       "  {'question': 'Shared file system implementation of the BlobStoreRepository',\n",
       "   'tags': ['Blob Storage', 'FileSystem']},\n",
       "  {'question': 'Is Cloud UI opensource?', 'tags': ['Cloud UI', 'Open Source']},\n",
       "  {'question': 'How to do fusion search and connect vector search with fulltext search',\n",
       "   'tags': ['Fusion Search', 'Vector Search', 'Fulltext Search']},\n",
       "  {'question': 'How to MATH fulltext Benchmarks of CrateDB',\n",
       "   'tags': ['CrateDB', 'Fulltext Search', 'Benchmarks']}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.886047Z",
     "start_time": "2024-05-25T22:31:21.553099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "# setup LLM Comparator\n",
    "import llm_comparator as llc\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "def safe_evaluator(i, evaluators, prediction, prediction_b, input_text):\n",
    "    if len(evaluators) < 3:\n",
    "        raise ValueError(\"Evaluators should be at least 3\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluators[i % 3].evaluate_string_pairs(\n",
    "            prediction=prediction if i % 2 == 0 else prediction_b,\n",
    "            prediction_b=prediction_b if i % 2 == 0 else prediction,\n",
    "            input=input_text\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {'score': 0, 'reasoning': 'Evaluation failed', 'value': 'Error'}\n",
    "\n",
    "\n",
    "def build_example(index: int, question: TaggedQuestion, chain_a, chain_b, raters=3):\n",
    "    prediction = chain_a.invoke(question['question'])\n",
    "    prediction_b = chain_b.invoke(question['question'])\n",
    "\n",
    "    individual_rater_scores: List[llc.RaterScore] = []\n",
    "\n",
    "    evaluators = [evaluator_openai, evaluator_openai,\n",
    "                  evaluator_openai, evaluator_openai]\n",
    "    # evaluators = [evaluator_openai, evaluator_cloude,\n",
    "    #               evaluator_openai, evaluator_cloude]\n",
    "\n",
    "    # parallelize\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        evaluations = list(executor.map(\n",
    "            lambda i: safe_evaluator(i, evaluators, prediction, prediction_b, question['question']),\n",
    "            range(raters * 2)\n",
    "        ))\n",
    "\n",
    "        for i, ev in enumerate(evaluations):\n",
    "            is_flipped = i % 2 == 1\n",
    "            # make score that is between 0 and 1, to be between -1.5 and 1.5\n",
    "            score = (ev['score'] - 0.5) * 3\n",
    "            if is_flipped:\n",
    "                score = -score\n",
    "\n",
    "            individual_rater_scores.append(\n",
    "                llc.RaterScore(\n",
    "                    is_flipped=is_flipped,\n",
    "                    score=score,\n",
    "                    rationale=ev['reasoning'],\n",
    "                    rating_label=ev['value']\n",
    "                )\n",
    "            )\n",
    "\n",
    "    avg_score = sum([r.score for r in individual_rater_scores]) / len(individual_rater_scores)\n",
    "\n",
    "    return llc.Example(\n",
    "        index=index,\n",
    "        input_text=question['question'],\n",
    "        tags=question[\"tags\"],\n",
    "        output_text_a=prediction,\n",
    "        output_text_b=prediction_b,\n",
    "        score=avg_score,\n",
    "        custom_fields={},\n",
    "        individual_rater_scores=individual_rater_scores,\n",
    "    )\n",
    "\n",
    "\n",
    "metadata = llc.Metadata(\n",
    "    source_path=\"Compare RAG search with CrateDB vector, fulltext, fusion and OpenAI\",\n",
    "    custom_fields_schema=[]\n",
    ")\n",
    "\n",
    "models: List[llc.Model] = [\n",
    "    llc.Model(\n",
    "        name=\"A\",\n",
    "    ),\n",
    "    llc.Model(\n",
    "        name=\"B\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "examples: List[llc.Example] = [build_example(i, x, chain_c, chain_b) for i, x in\n",
    "                               enumerate(categorised_questions['list'])]\n",
    "\n",
    "\n"
   ],
   "id": "4a2b951a8fca2e5e",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.890034Z",
     "start_time": "2024-05-25T22:34:18.887782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class RationalCluster(BaseModel):\n",
    "#     title: str = Field(description=\"the cluster title\")\n",
    "# \n",
    "# \n",
    "# class RationalClusterList(BaseModel):\n",
    "#     list: List[RationalCluster] = Field(description=\"list of clusters\")\n",
    "# \n",
    "# \n",
    "# parser_rat = JsonOutputParser(pydantic_object=RationalClusterList)\n",
    "# \n",
    "# prompt_rat = PromptTemplate(\n",
    "#     template=\"Act as a clustering algorithm. Define cluster names from this dataset: {rationals}.\\n{format_instructions}\\n\\n\",\n",
    "#     input_variables=[\"rationals\"],\n",
    "#     partial_variables={\n",
    "#         \"format_instructions\": parser_rat.get_format_instructions(),\n",
    "#     },\n",
    "# )\n",
    "# \n",
    "# chain_cluster_rationals = prompt_rat | model_openai | parser_rat\n",
    "# \n",
    "# \n",
    "# def categorise_questions(rationals: str) -> RationalClusterList:\n",
    "#     try:\n",
    "#         return chain_cluster_rationals.invoke({\"rationals\": rationals})\n",
    "#     except BaseException as e:\n",
    "#         return None"
   ],
   "id": "cb8d8343921ec811",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.892561Z",
     "start_time": "2024-05-25T22:34:18.890649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# from langchain.chains.combine_documents.reduce import ReduceDocumentsChain\n",
    "# from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "# from langchain_core.documents import Document\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# \n",
    "# rationales: List[Document] = []\n",
    "# for example in examples:\n",
    "#     for rater in example.individual_rater_scores:\n",
    "#         rationales.append(Document(\n",
    "#             page_content=rater.rationale,\n",
    "#             metadata={\"source\": example.input_text}\n",
    "#         ))\n",
    "# \n",
    "# map_template_name = PromptTemplate(input_variables=['docs'],\n",
    "#                                    template=\"\"\"\"The following is a set of documents\n",
    "# {docs}\n",
    "# Based on this list of docs, give me main key points\n",
    "# Helpful Answer:\"\"\")\n",
    "# map_chain = LLMChain(llm=model_openai, prompt=map_template_name)\n",
    "# # map_chain = map_template_name | model_openai | StrOutputParser()\n",
    "# \n",
    "# combine_documents_chain = StuffDocumentsChain(\n",
    "#     llm_chain=map_chain, document_variable_name=\"docs\"\n",
    "# )\n",
    "# reduce_documents_chain = ReduceDocumentsChain(\n",
    "#     # This is final chain\n",
    "#     combine_documents_chain=combine_documents_chain,\n",
    "#     # If documents exceed context for `StuffDocumentsChain`\n",
    "#     collapse_documents_chain=combine_documents_chain,\n",
    "#     # The maximum number of tokens to group documents into.\n",
    "#     token_max=500,\n",
    "# )\n",
    "# \n",
    "# output = reduce_documents_chain.run(rationales)\n",
    "# print(output)\n",
    "\n"
   ],
   "id": "c50a38cbbbf67201",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.895833Z",
     "start_time": "2024-05-25T22:34:18.893952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# select half of the rationales\n",
    "# rationales_sample = rationales[:len(rationales) // 3]\n",
    "# rationales_str_nai = \"\\n\".join([r.page_content for r in rationales_sample])\n",
    "# rationales_str_nai"
   ],
   "id": "8a78b77405f4cb1c",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.897803Z",
     "start_time": "2024-05-25T22:34:18.896358Z"
    }
   },
   "cell_type": "code",
   "source": "# queries_cat = \"\\n\".join(questions)",
   "id": "de6068998dfacb28",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.899771Z",
     "start_time": "2024-05-25T22:34:18.898389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cats = categorise_questions(queries_cat)\n",
    "# cats"
   ],
   "id": "3271f51244317c03",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.902119Z",
     "start_time": "2024-05-25T22:34:18.900289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rationale_clusters: List[llc.RationaleCluster] = [\n",
    "    llc.RationaleCluster(\n",
    "        title=\"provide more details\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"is more engaging\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"directly answers the question\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"has more references\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"has code examples\",\n",
    "    ),\n",
    "]\n",
    "\n"
   ],
   "id": "39aa90f8c32a49ca",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:34:18.904767Z",
     "start_time": "2024-05-25T22:34:18.902768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def measure_similarities(rational_cluster_emb: List[List[float]], rational_emb: List[float]) -> List[List[float]]:\n",
    "    b = rational_emb\n",
    "    return [\n",
    "        dot(a, b) / (norm(a) * norm(b)) for a in rational_cluster_emb\n",
    "    ]\n",
    "\n"
   ],
   "id": "3899d8f8178d9e85",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:40:22.736828Z",
     "start_time": "2024-05-25T22:34:18.905213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# enhance each example with rationale_list. \n",
    "for example in examples:\n",
    "    rationale_clusters_emb_list = embeddings.embed_documents([r.title for r in rationale_clusters])\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        extracted_list = list(executor.map(\n",
    "            lambda rater_score: extract_reasoning(rater_score.rationale),\n",
    "            example.individual_rater_scores\n",
    "        ))\n",
    "        for extracted in extracted_list:\n",
    "            if extracted and 'list' in extracted and len(extracted['list']) > 0:\n",
    "                example.rationale_list = [llc.Rational(\n",
    "                    rationale=r['rationale'],\n",
    "                    paraphrased_rationales=[],\n",
    "                    similarities=measure_similarities(rationale_clusters_emb_list,\n",
    "                                                      embeddings.embed_query(r['rationale'])),\n",
    "                ) for r in extracted['list']]\n"
   ],
   "id": "2c9778cf0ced225a",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:40:22.740367Z",
     "start_time": "2024-05-25T22:40:22.738643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for example in examples:\n",
    "#     score = example.score\n",
    "# \n",
    "#     rationale_avg_score = [r.score for r in example.rationale_list]\n",
    "#     rationale_avg_score = sum(rationale_avg_score) / len(rationale_avg_score) if rationale_avg_score else 0\n",
    "# \n",
    "#     print(f\"Query: {example.input_text}\")\n",
    "#     print(f\" -score {score} vs rationale {rationale_avg_score}\")\n",
    "#     for rationale in example.rationale_list:\n",
    "#         print(f\"  -{rationale.category} {rationale.score} {rationale.rationale}\")"
   ],
   "id": "ac5be7acb5e7a4ff",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T22:40:22.744699Z",
     "start_time": "2024-05-25T22:40:22.740814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llcset = llc.LLMComparatorData(\n",
    "    metadata=metadata,\n",
    "    models=models,\n",
    "    examples=examples,\n",
    "    rationale_clusters=rationale_clusters,\n",
    ")\n",
    "\n",
    "with open(\"eval-c-b-chunk300.json\", \"w\") as f:\n",
    "    f.write(llcset.to_json())"
   ],
   "id": "a16ff626e7877db8",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of evaluation results\n",
    "- Which variant was preferred more?\n",
    "- What is probability that people presented with a variant A over B will be more happy?\n",
    "- Which prediction variant on average performed better?\n",
    "- What is distribution of scores for each prediction variant?"
   ],
   "id": "b76c224e4159c231"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
