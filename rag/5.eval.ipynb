{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%pip install --upgrade --quiet pip setuptools wheel matplotlib seaborn\n",
    "%pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken crate 'crate[sqlalchemy]' pandas jq \n",
    "%pip install --use-pep517 --quiet python-dotenv\n",
    "%pip install --quiet langchain-google-genai\n",
    "%pip install -qU langchain-anthropic"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate RAG search with CrateDB vector, fulltext, fusion and OpenAI",
   "id": "5410104937328c86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup environment variables",
   "id": "26168fafe85c0e89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T22:11:34.576657Z",
     "start_time": "2024-05-20T22:11:34.552962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "e4a28f2ab8e8b4df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## setup embeddings",
   "id": "331beb594f3a2037"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T22:11:37.040962Z",
     "start_time": "2024-05-20T22:11:36.105519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "len(embeddings.embed_query(\"a\"))"
   ],
   "id": "ae2043d7eec255f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T22:11:37.595405Z",
     "start_time": "2024-05-20T22:11:37.592874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn_url = \"crate://{user}:{password}@{server}\".format(\n",
    "    user=os.environ[\"CRATEDB_USER\"],\n",
    "    password=os.environ[\"CRATEDB_PASS\"],\n",
    "    server=os.environ[\"CRATEDB_SERVER\"],\n",
    ")\n",
    "conn_url"
   ],
   "id": "de9c0e56bb15743f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crate://crate:@localhost:4200'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:02:04.245431Z",
     "start_time": "2024-05-24T19:02:02.973583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# open file\n",
    "from langchain_community.document_loaders import JSONLoader, DirectoryLoader\n",
    "\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"source_url\"] = record.get(\"url\")\n",
    "    metadata[\"source_title\"] = record.get(\"title\")\n",
    "\n",
    "    if \"source\" in metadata:\n",
    "        metadata[\"source\"] = metadata[\"source_url\"]\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    './',\n",
    "    glob=\"everything-*.json\",\n",
    "    loader_cls=JSONLoader,\n",
    "    loader_kwargs={\n",
    "        \"jq_schema\": \".[]\",\n",
    "        \"text_content\": False,\n",
    "        \"content_key\": \"html\",\n",
    "        \"metadata_func\": metadata_func,\n",
    "    }\n",
    ")\n",
    "\n",
    "data = loader.load()\n",
    "# data[:1]"
   ],
   "id": "44bfb1096b01b12b",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:02:04.949478Z",
     "start_time": "2024-05-24T19:02:04.333632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split documents\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "    ],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "docs_splits = text_splitter.split_documents(data)\n",
    "# docs_splits[:2]"
   ],
   "id": "5ae87cfd6c484e9",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG search, indexing pipeline    ",
   "id": "a0afa7c55d8d850b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:02:06.444494Z",
     "start_time": "2024-05-24T19:02:06.440623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic \n"
   ],
   "id": "f595efc8735a31cc",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:07:33.906945Z",
     "start_time": "2024-05-24T19:02:07.096722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.vectorstore.crate import CrateVectorStore\n",
    "\n",
    "vectorstore = CrateVectorStore.from_documents(\n",
    "    # assumes that data was imported already\n",
    "    # allow faster recomputation of notebook, without need of reindexing\n",
    "    # documents=[],\n",
    "    documents=docs_splits,\n",
    "    embedding=embeddings,\n",
    "    database_kwargs={\n",
    "        \"database_uri\": conn_url,\n",
    "    },\n",
    "    vectorstore_kwargs={\n",
    "       \"drop_if_exists\" : True,\n",
    "    },\n",
    ")\n",
    "vectorstore"
   ],
   "id": "665ce2d16282637f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rag.vectorstore.crate.CrateVectorStore at 0x333733350>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:07:33.910034Z",
     "start_time": "2024-05-24T19:07:33.908063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_a = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 10, 'fetch_k': 100, \"algorith\": \"knn\"}\n",
    ")\n",
    "\n",
    "retriever_b = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 10, 'fetch_k': 100, \"algorith\": \"fulltext\"}\n",
    ")\n",
    "\n",
    "retriever_c = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        retriever_a,\n",
    "        retriever_b\n",
    "    ],\n",
    "    weights=[0.5, 0.5],\n",
    ")"
   ],
   "id": "781dc12e0c5b9fa7",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:07:33.912696Z",
     "start_time": "2024-05-24T19:07:33.910455Z"
    }
   },
   "cell_type": "code",
   "source": "import json",
   "id": "11bbcee8796a3715",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:08.148725Z",
     "start_time": "2024-05-24T19:10:00.859451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "template = \"\"\"Answer the question based only on the context, if possible use links to reference the source, use markdown, avoid answering when the context and question are not related.\n",
    "\n",
    "today date is 2024 April 3rd\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model_openai = ChatOpenAI()\n",
    "model_geminai = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "model_cloude = ChatAnthropic(model=\"claude-3-opus-20240229\", temperature=0.1)\n",
    "\n",
    "def format_docs(docs):\n",
    "    breakpoint()\n",
    "    return json.dumps([{\"text\": d.page_content, \"source\": d.metadata.get('source')} for d in docs])\n",
    "\n",
    "\n",
    "chain_a = (\n",
    "        {\"context\": retriever_a | format_docs,\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_b = (\n",
    "        {\"context\": retriever_b | format_docs,\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_c = (\n",
    "        {\"context\": retriever_c | format_docs,\n",
    "         \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model_openai\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# result = chain.invoke(\"How to limit permissions?\")\n",
    "# result = chain.invoke(\" How AWS marketplace works, and why I cannot see deployment in my account?\")\n",
    "# result = chain.invoke(\"What are edge regions and how to use them?\")\n",
    "result = chain_a.invoke(\"Write me example of using blobs?\")\n",
    "# result = chain.invoke(\"How to use BLOB store in CrateDB? and what are the benefits?\")\n",
    "result\n"
   ],
   "id": "76601e20f9f80251",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To use BLOBs in CrateDB, you would need to follow these steps:\\n\\n1. **Creating a BLOB Table**: Before adding a BLOB to CrateDB, you must create a BLOB table. This can be done using the Crate Shell (CraSh) by issuing an SQL statement like this:\\n   ```sh\\n   crash -c \"create blob table myblobs clustered into 3 shards with (number_of_replicas=1)\"\\n   ```\\n   Source: [CrateDB Documentation](https://cratedb.com/docs/crate/reference/en/5.6/general/blobs.html)\\n\\n2. **Uploading BLOBs**: To upload a BLOB, you need to know the SHA1 hash of the BLOB upfront. You can compute the hash using a command like this in Python:\\n   ```sh\\n   python -c \\'import hashlib;print(hashlib.sha1(\"contents\".encode(\"utf-8\")).hexdigest())\\'\\n   ```\\n   Once you have the hash, you can upload the BLOB by issuing a PUT request. \\n   Source: [CrateDB Blog](https://cratedb.com/blog/using-crate-as-a-blobstore)\\n\\n3. **Listing & Querying BLOBs**: To list all BLOBs inside a BLOB table, you can use a SELECT statement like this:\\n   ```sh\\n   crash -c \"select digest, last_modified from blob.myblobs\"\\n   ```\\n   This allows you to see the digests and modification timestamps of the BLOBs stored in the table.\\n   Source: [CrateDB Blog](https://cratedb.com/blog/using-crate-as-a-blobstore)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:16.651301Z",
     "start_time": "2024-05-24T19:10:08.149917Z"
    }
   },
   "cell_type": "code",
   "source": "model_cloude.invoke(\"Write me poem\")",
   "id": "4bc01063681dba7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's a poem for you:\\n\\nIn the tapestry of life, threads intertwine,\\nWeaving moments of joy, love, and sometimes pain.\\nEach stitch a memory, a story to tell,\\nOf laughter, tears, and dreams that dwell.\\n\\nColors blend and patterns form,\\nCreating a masterpiece, vibrant and warm.\\nThrough the ups and downs, the twists and turns,\\nThe fabric of existence forever churns.\\n\\nYet in the midst of chaos and strife,\\nThere's beauty to be found, a zest for life.\\nIn the simple things, the everyday,\\nA smile, a hug, a word to say.\\n\\nSo let us cherish the moments we hold dear,\\nAnd face the future without fear.\\nFor in this grand design, we play a part,\\nStitching our stories, with love in our heart.\", response_metadata={'id': 'msg_01DojgM1ickYARzXhEsCexcb', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 10, 'output_tokens': 196}}, id='run-238434b4-9123-4319-99be-a211693669b9-0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:16.657803Z",
     "start_time": "2024-05-24T19:10:16.653407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(result))"
   ],
   "id": "30b414b6a3321c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "To use BLOBs in CrateDB, you would need to follow these steps:\n\n1. **Creating a BLOB Table**: Before adding a BLOB to CrateDB, you must create a BLOB table. This can be done using the Crate Shell (CraSh) by issuing an SQL statement like this:\n   ```sh\n   crash -c \"create blob table myblobs clustered into 3 shards with (number_of_replicas=1)\"\n   ```\n   Source: [CrateDB Documentation](https://cratedb.com/docs/crate/reference/en/5.6/general/blobs.html)\n\n2. **Uploading BLOBs**: To upload a BLOB, you need to know the SHA1 hash of the BLOB upfront. You can compute the hash using a command like this in Python:\n   ```sh\n   python -c 'import hashlib;print(hashlib.sha1(\"contents\".encode(\"utf-8\")).hexdigest())'\n   ```\n   Once you have the hash, you can upload the BLOB by issuing a PUT request. \n   Source: [CrateDB Blog](https://cratedb.com/blog/using-crate-as-a-blobstore)\n\n3. **Listing & Querying BLOBs**: To list all BLOBs inside a BLOB table, you can use a SELECT statement like this:\n   ```sh\n   crash -c \"select digest, last_modified from blob.myblobs\"\n   ```\n   This allows you to see the digests and modification timestamps of the BLOBs stored in the table.\n   Source: [CrateDB Blog](https://cratedb.com/blog/using-crate-as-a-blobstore)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "b1aed295b7496890"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:16.665072Z",
     "start_time": "2024-05-24T19:10:16.660583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "questions = [\n",
    "    \"Write me example of using blobs?\",\n",
    "    \"How to use BLOB store in CrateDB? and what are the benefits?\",\n",
    "    \"How to limit permissions?\",\n",
    "    \"How AWS marketplace works, and why I cannot see deployment in my account?\",\n",
    "    \"What are edge regions and how to use them?\",\n",
    "    \"What are recent blog posts about CrateDB?\",\n",
    "    \"Write me example python code to use CrateDB?\",\n",
    "    \"Write me example golang code to use CrateDB?\",\n",
    "    \"create RAG search with CrateDB and OpenAI?\",\n",
    "    \"how to alter table and add fulltext index?\",\n",
    "    \"how to alter table and add vector type field that allows for KNN search?\",\n",
    "    \"create table with fields ID, name, vector, and index vector field for KNN search?\",\n",
    "    \"What are limits and limitations of CrateDB?\",\n",
    "    \"What are the benefits of using CrateDB?\",\n",
    "    \"Does index creation block write operations?\",\n",
    "    \"Does crate supports conditional indices\",\n",
    "    \"How to create ID field that is autoincremented?\",\n",
    "    \"how to create analysers for fulltext search?\",\n",
    "    \"give me information about password and admin\",\n",
    "    \"Shared file system implementation of the BlobStoreRepository\",\n",
    "    \"Is Cloud UI opensource?\",\n",
    "    \"How to do fusion search and connect vector search with fulltext search\",\n",
    "    \"How to MATH fulltext \"\n",
    "    \"Benchmarks of CrateDB\",\n",
    "]"
   ],
   "id": "cede734d54699adc",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:16.674756Z",
     "start_time": "2024-05-24T19:10:16.666332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "# from langchain.evaluation.criteria import Criteria\n",
    "# \n",
    "# criteria = [\n",
    "#     Criteria.COHERENCE,\n",
    "#     Criteria.RELEVANCE,\n",
    "#     Criteria.DETAIL,\n",
    "#     Criteria.HARMFULNESS,\n",
    "#     Criteria.HELPFULNESS,\n",
    "# ]\n",
    "\n",
    "criteria2 = {\n",
    "    \"runnable\": \"Software engineer who is looking for information can copy and paste the code and it should work\",\n",
    "    \"relevance\": \"The answer is relevant to the question\",\n",
    "    \"grounded\": \"The answer links to the source of the information\",\n",
    "    \"coherence\": \"The answer is coherent and makes sense\",\n",
    "    \"detail\": \"The answer is detailed and provides enough information\",\n",
    "    \"helpfulness\": \"The answer is helpful and provides value\",\n",
    "    \"direct\": \"The answer directly answers the question\",\n",
    "    \"code\": \"The answer contains code that can be copied and pasted\",\n",
    "    \"reference\": \"The answer contains reference to the source in form of URL\",\n",
    "}\n",
    "\n",
    "evaluator_openai = load_evaluator(\"pairwise_string\", criteria=criteria2, llm=model_openai)\n",
    "evaluator_gemini = load_evaluator(\"pairwise_string\", criteria=criteria2, llm=model_geminai)\n",
    "evaluator_cloude = load_evaluator(\"pairwise_string\", criteria=criteria2, llm=model_cloude)\n"
   ],
   "id": "7f1528481846d709",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n",
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n",
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:47.879396Z",
     "start_time": "2024-05-24T19:10:16.676456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"Write me example of using blobs?\"\n",
    "prediction = chain_a.invoke(question)\n",
    "prediction_b = chain_b.invoke(question)\n",
    "\n",
    "ev = evaluator_cloude.evaluate_string_pairs(\n",
    "    prediction=prediction,\n",
    "    prediction_b=prediction_b,\n",
    "    input=question\n",
    ")\n",
    "\n"
   ],
   "id": "f46460593bc5d2d5",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:47.881872Z",
     "start_time": "2024-05-24T19:10:47.879909Z"
    }
   },
   "cell_type": "code",
   "source": "ev",
   "id": "2bfb0ad031d27cad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': \"In comparing the two responses, both provide relevant information on how to use BLOBs with CrateDB. However, Assistant A's response is more comprehensive and helpful for a software engineer looking to implement this functionality.\\n\\nAssistant A provides a clear, step-by-step example of creating a BLOB table using the Crate Shell, including the specific command to use. They also provide a runnable example of uploading a BLOB using a PUT request, including the curl command and the URL structure. Additionally, they include a direct link to the official CrateDB documentation for further reference.\\n\\nWhile Assistant B also provides the command to create a BLOB table, they do not provide a complete example of uploading a BLOB. Instead, they suggest using a Python one-liner to get the SHA1 hash, which, although helpful, is not as directly relevant to the question of using BLOBs with CrateDB. They mention that you can list, query, download, and delete BLOBs but do not provide specific examples or commands for these operations.\\n\\nIn terms of the evaluation criteria, both answers are relevant and grounded, but Assistant A's response is more detailed, coherent, and directly answers the question with runnable code examples. Therefore, Assistant A's response would be more helpful for a software engineer looking to implement BLOB functionality in CrateDB.\\n\\n[[A]]\",\n",
       " 'value': 'A',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:47.886109Z",
     "start_time": "2024-05-24T19:10:47.882341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class InferredRational(BaseModel):\n",
    "    rationale: str = Field(description=\"rational of the labeler\")\n",
    "    category: str = Field(description=\"category used for evaluation\")\n",
    "    score: float = Field(\n",
    "        description=\"Score -1.5 to 1.5. Where -1.5 is below expectations in the rational category, and 1.5 is above expectations in the rational category.\")\n",
    "\n",
    "\n",
    "class RationalList(BaseModel):\n",
    "    list: List[InferredRational] = Field(description=\"list of rationals used to asses quality by labeler\")\n",
    "\n",
    "\n",
    "parser_ret = JsonOutputParser(pydantic_object=RationalList)\n",
    "\n",
    "prompt_reg = PromptTemplate(\n",
    "    template=\"Extract labeler rational following criterias {criterias}.\\n{format_instructions}\\n{reasoning}\\n\",\n",
    "    input_variables=[\"reasoning\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser_ret.get_format_instructions(),\n",
    "        \"criterias\": json.dumps(criteria2, indent=2)\n",
    "    },\n",
    ")\n",
    "\n",
    "chain_reasoning_extract = prompt_reg | model_openai | parser_ret\n",
    "\n",
    "\n",
    "def extract_reasoning(reasoning) -> RationalList:\n",
    "    try:\n",
    "        return chain_reasoning_extract.invoke({\"reasoning\": reasoning})\n",
    "    except BaseException as e:\n",
    "        return None"
   ],
   "id": "2330d5b9dacc75e1",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:51.113821Z",
     "start_time": "2024-05-24T19:10:47.886567Z"
    }
   },
   "cell_type": "code",
   "source": "extract_reasoning(ev['reasoning'])",
   "id": "9da0a51fb09d76c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [{'rationale': 'Provides clear, step-by-step example of creating a BLOB table using Crate Shell',\n",
       "   'category': 'detail',\n",
       "   'score': 1.2},\n",
       "  {'rationale': 'Includes runnable example of uploading a BLOB using PUT request',\n",
       "   'category': 'runnable',\n",
       "   'score': 1.4},\n",
       "  {'rationale': 'Directly links to official CrateDB documentation for further reference',\n",
       "   'category': 'reference',\n",
       "   'score': 1.3},\n",
       "  {'rationale': 'Answer is detailed, coherent, and directly answers the question with runnable code examples',\n",
       "   'category': 'helpfulness',\n",
       "   'score': 1.5}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:10:51.124278Z",
     "start_time": "2024-05-24T19:10:51.118544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class TaggedQuestion(BaseModel):\n",
    "    question: str = Field(description=\"the original question\")\n",
    "    tags: List[str] = Field(description=\"the list of tags that best categorize the question\")\n",
    "\n",
    "\n",
    "class TaggedQuestionList(BaseModel):\n",
    "    list: List[TaggedQuestion] = Field(description=\"list of categorized questions\")\n",
    "\n",
    "\n",
    "parser_cat = JsonOutputParser(pydantic_object=TaggedQuestionList)\n",
    "\n",
    "prompt_cat = PromptTemplate(\n",
    "    template=\"Categorize question {questions}.\\n{format_instructions}\\n\\n\",\n",
    "    input_variables=[\"reasoning\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser_cat.get_format_instructions(),\n",
    "        \"questions\": json.dumps(questions, indent=2)\n",
    "    },\n",
    ")\n",
    "\n",
    "chain_tag_question = prompt_cat | model_openai | parser_cat\n",
    "\n",
    "\n",
    "def categorise_questions(questions: List[str]) -> TaggedQuestionList:\n",
    "    try:\n",
    "        return chain_tag_question.invoke({\"questions\": questions})\n",
    "    except BaseException as e:\n",
    "        return None"
   ],
   "id": "c7b2b72aaa04a542",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:11:03.768601Z",
     "start_time": "2024-05-24T19:10:51.126634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorised_questions = categorise_questions(questions)\n",
    "categorised_questions"
   ],
   "id": "153d4258ba9f1b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [{'question': 'Write me example of using blobs?',\n",
       "   'tags': ['database', 'blob']},\n",
       "  {'question': 'How to use BLOB store in CrateDB? and what are the benefits?',\n",
       "   'tags': ['database', 'blob', 'CrateDB']},\n",
       "  {'question': 'How to limit permissions?', 'tags': ['security']},\n",
       "  {'question': 'How AWS marketplace works, and why I cannot see deployment in my account?',\n",
       "   'tags': ['AWS', 'deployment']},\n",
       "  {'question': 'What are edge regions and how to use them?',\n",
       "   'tags': ['edge computing']},\n",
       "  {'question': 'What are recent blog posts about CrateDB?',\n",
       "   'tags': ['CrateDB', 'blog']},\n",
       "  {'question': 'Write me example python code to use CrateDB?',\n",
       "   'tags': ['CrateDB', 'python']},\n",
       "  {'question': 'Write me example golang code to use CrateDB?',\n",
       "   'tags': ['CrateDB', 'golang']},\n",
       "  {'question': 'create RAG search with CrateDB and OpenAI?',\n",
       "   'tags': ['CrateDB', 'search']},\n",
       "  {'question': 'how to alter table and add fulltext index?',\n",
       "   'tags': ['database', 'indexing']},\n",
       "  {'question': 'how to alter table and add vector type field that allows for KNN search?',\n",
       "   'tags': ['database', 'KNN', 'indexing']},\n",
       "  {'question': 'create table with fields ID, name, vector, and index vector field for KNN search?',\n",
       "   'tags': ['database', 'table design', 'KNN']},\n",
       "  {'question': 'What are limits and limitations of CrateDB?',\n",
       "   'tags': ['CrateDB', 'limitations']},\n",
       "  {'question': 'What are the benefits of using CrateDB?',\n",
       "   'tags': ['CrateDB', 'benefits']},\n",
       "  {'question': 'Does index creation block write operations?',\n",
       "   'tags': ['indexing', 'performance']},\n",
       "  {'question': 'Does crate supports conditional indices',\n",
       "   'tags': ['CrateDB', 'indexing']},\n",
       "  {'question': 'How to create ID field that is autoincremented?',\n",
       "   'tags': ['database', 'autoincrement']},\n",
       "  {'question': 'how to create analysers for fulltext search?',\n",
       "   'tags': ['database', 'fulltext search']},\n",
       "  {'question': 'give me information about password and admin',\n",
       "   'tags': ['security', 'authentication']},\n",
       "  {'question': 'Shared file system implementation of the BlobStoreRepository',\n",
       "   'tags': ['database', 'blob', 'file system']},\n",
       "  {'question': 'Is Cloud UI opensource?', 'tags': ['Cloud', 'opensource']},\n",
       "  {'question': 'How to do fusion search and connect vector search with fulltext search',\n",
       "   'tags': ['search', 'fusion', 'vector search', 'fulltext search']},\n",
       "  {'question': 'How to MATH fulltext Benchmarks of CrateDB',\n",
       "   'tags': ['CrateDB', 'benchmarking']}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:19:03.838847Z",
     "start_time": "2024-05-24T19:11:03.769538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "# setup LLM Comparator\n",
    "import llm_comparator as llc\n",
    "import concurrent.futures\n",
    "\n",
    "def safe_evaluator(i, evaluators, prediction, prediction_b, input_text):\n",
    "    try:\n",
    "        result = evaluators[i%3].evaluate_string_pairs(\n",
    "            prediction=prediction if i % 2 == 0 else prediction_b,\n",
    "            prediction_b=prediction_b if i % 2 == 0 else prediction,\n",
    "            input=input_text\n",
    "        )\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {'score': 0, 'reasoning': 'Evaluation failed', 'value': 'Error'}\n",
    "    \n",
    "def build_example(index: int, question: TaggedQuestion, chain_a, chain_b, raters=3):\n",
    "    prediction = chain_a.invoke(question['question'])\n",
    "    prediction_b = chain_b.invoke(question['question'])\n",
    "\n",
    "    individual_rater_scores: List[llc.RaterScore] = []\n",
    "    \n",
    "    evaluators = [evaluator_openai, evaluator_cloude,\n",
    "                  evaluator_openai, evaluator_cloude]\n",
    "\n",
    "    # parallelize\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        evaluations = list(executor.map(\n",
    "            lambda i: safe_evaluator(i, evaluators, prediction, prediction_b, question['question']),\n",
    "            range(raters * 2)\n",
    "        ))\n",
    "\n",
    "        for i, ev in enumerate(evaluations):\n",
    "            is_flipped = i % 2 == 1\n",
    "            # make score that is between 0 and 1, to be between -1.5 and 1.5\n",
    "            score = (ev['score'] - 0.5) * 3\n",
    "            if is_flipped:\n",
    "                score = -score\n",
    "\n",
    "            individual_rater_scores.append(\n",
    "                llc.RaterScore(\n",
    "                    is_flipped=is_flipped,\n",
    "                    score=score,\n",
    "                    rationale=ev['reasoning'],\n",
    "                    rating_label=ev['value']\n",
    "                )\n",
    "            )\n",
    "\n",
    "    avg_score = sum([r.score for r in individual_rater_scores]) / len(individual_rater_scores)\n",
    "\n",
    "    return llc.Example(\n",
    "        index=index,\n",
    "        input_text=question['question'],\n",
    "        tags=question[\"tags\"],\n",
    "        output_text_a=prediction,\n",
    "        output_text_b=prediction_b,\n",
    "        score=avg_score,\n",
    "        custom_fields={},\n",
    "        individual_rater_scores=individual_rater_scores,\n",
    "    )\n",
    "\n",
    "\n",
    "metadata = llc.Metadata(\n",
    "    source_path=\"Compare RAG search with CrateDB vector, fulltext, fusion and OpenAI\",\n",
    "    custom_fields_schema=[]\n",
    ")\n",
    "\n",
    "models: List[llc.Model] = [\n",
    "    llc.Model(\n",
    "        name=\"A\",\n",
    "    ),\n",
    "    llc.Model(\n",
    "        name=\"B\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "examples: List[llc.Example] = [build_example(i, x, chain_a, chain_b) for i, x in\n",
    "                               enumerate(categorised_questions['list'])]\n",
    "\n",
    "\n"
   ],
   "id": "4a2b951a8fca2e5e",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:19:03.845231Z",
     "start_time": "2024-05-24T19:19:03.841892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rationale_clusters: List[llc.RationaleCluster] = [\n",
    "    llc.RationaleCluster(\n",
    "        title=\"provide more details\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"is more engaging\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"directly answers the question\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"has more references\",\n",
    "    ),\n",
    "    llc.RationaleCluster(\n",
    "        title=\"has code examples\",\n",
    "    ),\n",
    "]\n",
    "\n"
   ],
   "id": "39aa90f8c32a49ca",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:19:03.849292Z",
     "start_time": "2024-05-24T19:19:03.846166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def measure_similarities(rational_cluster_emb: List[List[float]], rational_emb: List[float]) -> List[List[float]]:\n",
    "    b = rational_emb\n",
    "    return [\n",
    "        dot(a, b) / (norm(a) * norm(b)) for a in rational_cluster_emb\n",
    "    ]\n",
    "\n"
   ],
   "id": "3899d8f8178d9e85",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:26:38.831664Z",
     "start_time": "2024-05-24T19:19:03.850145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# enhance each example with rationale_list. \n",
    "for example in examples:\n",
    "    rationale_clusters_emb_list = embeddings.embed_documents([r.title for r in rationale_clusters])\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        extracted_list = list(executor.map(\n",
    "            lambda rater_score: extract_reasoning(rater_score.rationale),\n",
    "            example.individual_rater_scores\n",
    "        ))\n",
    "        for extracted in extracted_list:\n",
    "            if extracted and 'list' in extracted and len(extracted['list']) > 0:\n",
    "                example.rationale_list = [llc.Rational(\n",
    "                    rationale=r['rationale'],\n",
    "                    paraphrased_rationales=[],\n",
    "                    similarities=measure_similarities(rationale_clusters_emb_list,\n",
    "                                                      embeddings.embed_query(r['rationale'])),\n",
    "                ) for r in extracted['list']]\n"
   ],
   "id": "2c9778cf0ced225a",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:26:38.834469Z",
     "start_time": "2024-05-24T19:26:38.832759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ac5be7acb5e7a4ff",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T19:26:38.844244Z",
     "start_time": "2024-05-24T19:26:38.835128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llcset = llc.LLMComparatorData(\n",
    "    metadata=metadata,\n",
    "    models=models,\n",
    "    examples=examples,\n",
    "    rationale_clusters=rationale_clusters,\n",
    ")\n",
    "\n",
    "with open(\"eval.json\", \"w\") as f:\n",
    "    f.write(llcset.to_json())"
   ],
   "id": "a16ff626e7877db8",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis of evaluation results\n",
    "- Which variant was preferred more?\n",
    "- What is probability that people presented with a variant A over B will be more happy?\n",
    "- Which prediction variant on average performed better?\n",
    "- What is distribution of scores for each prediction variant?"
   ],
   "id": "b76c224e4159c231"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
